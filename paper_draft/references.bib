@article{laban2025lic,
  title={LLMs Get Lost in Multi-Turn Conversation},
  author={Laban, Philippe and Hayashi, Hiroaki and Zhou, Yichen and Neville, Jennifer},
  journal={arXiv preprint arXiv:2505.06120},
  year={2025}
}

@article{dongre2025drift,
  title={Drift No More? Context Equilibria in Multi-Turn {LLM} Interactions},
  author={Dongre, Adarsh and Rossi, Ryan A and Lai, Tung and Yoon, Sungchul and Hakkani-Tur, Dilek and Bui, Trung},
  journal={arXiv preprint arXiv:2510.07777},
  year={2025}
}

@article{pan2025userassistant,
  title={User-Assistant Bias in {LLMs}},
  author={Pan, Tianhao and Fan, Yihang and Xiong, Chenwei and Hahami, Ofir and Overwiening, Alexander and Xie, Yuxin},
  journal={arXiv preprint arXiv:2508.15815},
  year={2025}
}

@article{liu2025truthdecay,
  title={{TRUTH DECAY}: Quantifying Multi-Turn Sycophancy in Language Models},
  author={Liu, Soham and Jain, Rhythm and Takuri, Sreekar and Vege, Anirudh and Akalin, Selen and Zhu, William and O'Brien, Nicholas and Sharma, Arnav},
  journal={arXiv preprint arXiv:2503.11656},
  year={2025}
}

@article{hong2025syconbench,
  title={{SYCON-Bench}: Measuring Sycophancy in Multi-Turn Dialogues},
  author={Hong, Giwon and others},
  journal={arXiv preprint arXiv:2505.23840},
  year={2025}
}

@article{wang2023mint,
  title={{MINT}: Evaluating {LLMs} in Multi-turn Interaction with Tools and Language Feedback},
  author={Wang, Xingyao and others},
  journal={arXiv preprint arXiv:2309.10691},
  year={2023}
}

@article{gao2024refuel,
  title={{REFUEL}: Regressing the Relative Future for Multi-turn {RLHF} Policy Optimization},
  author={Gao, Zixuan and others},
  journal={arXiv preprint arXiv:2410.01088},
  year={2024}
}

@article{khalid2025ergo,
  title={{ERGO}: Entropy-guided Resetting for Generation Optimization},
  author={Khalid, Muhammad and others},
  journal={arXiv preprint arXiv:2505.17863},
  year={2025}
}

@article{flipflop2023,
  title={{FlipFlop}: Are You Sure? Challenging {LLMs}},
  author={Anonymous},
  journal={arXiv preprint arXiv:2311.08596},
  year={2023}
}

@article{russinovich2024crescendo,
  title={Crescendo: Multi-Turn {LLM} Jailbreak Attack},
  author={Russinovich, Mark and Salem, Ahmed and Eldan, Ronen},
  journal={arXiv preprint arXiv:2404.00657},
  year={2024}
}

@article{he2024multiif,
  title={Multi-{IF}: Benchmarking {LLMs} on Multi-Turn and Multilingual Instructions Following},
  author={He, Yun and others},
  journal={arXiv preprint arXiv:2410.15553},
  year={2024}
}

@inproceedings{kwan2024mteval,
  title={{MT-Eval}: A Multi-Turn Capabilities Evaluation Benchmark},
  author={Kwan, Wai-Chung and others},
  booktitle={Proceedings of EMNLP},
  year={2024}
}

@article{zheng2023mtbench,
  title={Judging {LLM-as-a-Judge} with {MT-Bench} and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
  journal={arXiv preprint arXiv:2306.05685},
  year={2023}
}

@article{almasi2025alignment,
  title={Alignment Drift in {CEFR}-prompted {LLMs}},
  author={Almasi, Mina and Kristensen-McLachlan, Ross Deans},
  journal={arXiv preprint arXiv:2503.04589},
  year={2025}
}

@article{zhou2025tempest,
  title={Tempest: Autonomous Multi-Turn Jailbreaking with Tree Search},
  author={Zhou, Yu and Arel, Itamar},
  year={2025}
}

@article{weng2025fitd,
  title={Foot-In-The-Door: A Multi-turn Jailbreak for {LLMs}},
  author={Weng, Zihao and others},
  year={2025}
}

@article{singhania2025mmart,
  title={{MM-ART}: Multi-lingual Multi-turn Automated Red Teaming for {LLMs}},
  author={Singhania, Anshuman and others},
  year={2025}
}

@article{neergaard2026boolq,
  title={Is Length Really A Liability? Multi-turn {LLM} Conversations using {BoolQ}},
  author={Neergaard, Mark and others},
  journal={arXiv preprint},
  year={2026}
}

@article{lin2025styleamnesia,
  title={Style Amnesia: Speaking Style Degradation in Multi-Turn Spoken Language Models},
  author={Lin, Zhihao and others},
  year={2025}
}

@article{clark2019boolq,
  title={{BoolQ}: Exploring the Surprising Difficulty of Natural Yes/No Questions},
  author={Clark, Christopher and Lee, Kenton and Chang, Ming-Wei and Kwiatkowski, Tom and Collins, Michael and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1905.10044},
  year={2019}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{rafailov2023direct,
  title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{li2025rlaar,
  title={{RLAAR}: Verifiable Accuracy and Abstention Rewards to Alleviate Lost-in-Conversation},
  author={Li, Zhenyu},
  journal={arXiv preprint arXiv:2506.05697},
  year={2025}
}

@article{hong2025rhea,
  title={Rhea: Role-aware Heuristic Episodic Attention for Conversational {LLMs}},
  author={Hong, Giwon and others},
  year={2025}
}

@article{liu2025flowkv,
  title={{FlowKV}: Multi-Turn {KV} Cache Management},
  author={Liu, Zihao and others},
  year={2025}
}

@article{hankache2025sensitivity,
  title={Evaluating the Sensitivity of {LLMs} to Prior Context},
  author={Hankache, Rima and others},
  journal={arXiv preprint arXiv:2505.08283},
  year={2025}
}
